{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MaaS Platform Documentation","text":"<p>Welcome to the Model-as-a-Service (MaaS) Platform documentation.</p> <p>The MaaS Platform enhances the model serving capabilities of Open Data Hub by adding a management layer for self-service access control, rate limiting, and tier-based subscriptions.</p> <p>Use this platform to streamline the deployment of your models, monitor usage, and effectively manage costs.</p>"},{"location":"#documentation-overview","title":"\ud83d\udcda Documentation Overview","text":""},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ul> <li>QuickStart Guide - Complete platform deployment instructions</li> <li>Architecture - Overview of the MaaS Platform architecture</li> </ul>"},{"location":"#configuration-management","title":"\u2699\ufe0f Configuration &amp; Management","text":"<ul> <li>Tier Management - Configuring subscription tiers and access control</li> <li>Model Setup - Setting up models for MaaS</li> <li>Self-Service Model Access - Managing model access and policies</li> </ul>"},{"location":"#advanced-administration","title":"\ud83d\udd27 Advanced Administration","text":"<ul> <li>Observability - Monitoring, metrics, and dashboards</li> </ul>"},{"location":"architecture/","title":"MaaS Platform Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>The MaaS Platform is designed as a cloud-native, Kubernetes-based solution that provides policy-based access control, rate limiting, and tier-based subscriptions for AI model serving. The architecture follows microservices principles and leverages OpenShift/Kubernetes native components for scalability and reliability.</p>"},{"location":"architecture/#architecture","title":"Architecture","text":""},{"location":"architecture/#high-level-architecture","title":"\ud83c\udfd7\ufe0f High-Level Architecture","text":"<p>The MaaS Platform is an end-to-end solution that leverages Kuadrant (Red Hat Connectivity Link) and Open Data Hub (Red Hat OpenShift AI)'s Model Serving capabilities to provide a fully managed, scalable, and secure self-service platform for AI model serving.</p> <p>All requests flow through the maas-default-gateway and RHCL components, which then route requests based on the path:</p> <ul> <li><code>/maas-api/*</code> requests \u2192 MaaS API (token retrieval, validates OpenShift Token via RHCL)</li> <li>Inference requests (<code>/v1/models</code>, <code>/v1/chat/completions</code>) \u2192 Model Serving (validates Service Account Token via RHCL)</li> </ul> <pre><code>graph TB\n    subgraph \"User Layer\"\n        User[Users]\n    end\n\n    subgraph \"Gateway &amp; Policy Layer\"\n        GatewayAPI[\"maas-default-gateway&lt;br/&gt;All Traffic Entry Point\"]\n        AuthPolicy[\"&lt;b&gt;Auth Policy&lt;/b&gt;&lt;br/&gt;Authorino&lt;br/&gt;Token Validation\"]\n        RateLimit[\"&lt;b&gt;Rate Limiting&lt;/b&gt;&lt;br/&gt;Limitador&lt;br/&gt;Usage Quotas\"]\n    end\n\n    subgraph \"Token Management Path\"\n        MaaSAPI[\"MaaS API&lt;br/&gt;Token Retrieval\"]\n    end\n\n    subgraph \"Model Serving Path\"\n        PathInference[\"Inference Service\"]\n        ModelServing[\"RHOAI Model Serving\"]\n    end\n\n    User --&gt;|\"All Requests\"| GatewayAPI\n    GatewayAPI --&gt;|\"All Traffic\"| AuthPolicy\n\n    AuthPolicy --&gt;|\"/maas-api&lt;br/&gt;Auth Only\"| MaaSAPI\n    MaaSAPI --&gt;|\"Returns Token\"| User\n\n    AuthPolicy --&gt;|\"Inference Traffic&lt;br/&gt;Auth + Rate Limit\"| RateLimit\n    RateLimit --&gt; PathInference\n    PathInference --&gt; ModelServing\n    ModelServing --&gt;|\"Returns Response\"| User\n\n    style MaaSAPI fill:#1976d2,stroke:#333,stroke-width:2px,color:#fff\n    style GatewayAPI fill:#7b1fa2,stroke:#333,stroke-width:2px,color:#fff\n    style AuthPolicy fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style RateLimit fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style PathInference fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style ModelServing fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"architecture/#architecture-details","title":"Architecture Details","text":"<p>The MaaS Platform architecture is designed to be modular and scalable. It is composed of the following components:</p> <ul> <li>maas-default-gateway: The single entry point for all traffic (both token requests and inference requests).</li> <li>RHCL (Red Hat Connectivity Link): The policy engine that handles authentication and authorization for all requests. Routes requests to appropriate backend based on path:</li> <li><code>/maas-api/*</code> \u2192 MaaS API (validates OpenShift tokens)</li> <li>Inference paths (<code>/v1/models</code>, <code>/v1/chat/completions</code>) \u2192 Model Serving (validates Service Account tokens)</li> <li>MaaS API: The central component for token generation and management, accessed via <code>/maas-api</code> path.</li> <li>Open Data Hub (Red Hat OpenShift AI): The model serving platform that handles inference requests.</li> </ul>"},{"location":"architecture/#detailed-component-architecture","title":"Detailed Component Architecture","text":""},{"location":"architecture/#maas-api-component-details","title":"MaaS API Component Details","text":"<p>The MaaS API provides a self-service platform for users to request tokens for their inference requests. All requests to the MaaS API pass through the <code>maas-default-gateway</code> where authentication is performed against the user's OpenShift token via the Auth Policy component. By leveraging Kubernetes native objects like ConfigMaps and ServiceAccounts, it offers model owners a simple way to configure access to their models based on a familiar group-based access control model.</p> <pre><code>graph TB\n    subgraph \"External Access\"\n        User[Users]\n        AdminUI[Admin/User UI]\n    end\n\n    subgraph \"Gateway &amp; Auth\"\n        Gateway[**maas-default-gateway**&lt;br/&gt;Entry Point]\n        AuthPolicy[**Auth Policy**&lt;br/&gt;Validates OpenShift Token]\n    end\n\n    subgraph \"MaaS API Service\"\n        API[**MaaS API**&lt;br/&gt;Go + Gin Framework]\n        TierMapping[**Tier Mapping Logic**]\n        TokenGen[**Service Account Token Generation**]\n    end\n\n    subgraph \"Configuration\"\n        ConfigMap[**ConfigMap**&lt;br/&gt;tier-to-group-mapping]\n        K8sGroups[**Kubernetes Groups**&lt;br/&gt;tier-free-users&lt;br/&gt;tier-premium-users&lt;br/&gt;tier-enterprise-users]\n    end\n\n    subgraph \"free namespace\"\n        FreeSA1[**ServiceAccount**&lt;br/&gt;freeuser1-sa]\n        FreeSA2[**ServiceAccount**&lt;br/&gt;freeuser2-sa]\n    end\n\n    subgraph \"premium namespace\"\n        PremiumSA1[**ServiceAccount**&lt;br/&gt;prem-user1-sa]\n    end\n\n    subgraph \"enterprise namespace\"\n        EnterpriseSA1[**ServiceAccount**&lt;br/&gt;ent-user1-sa]\n    end\n\n    User --&gt;|\"Request with&lt;br/&gt;OpenShift Token\"| Gateway\n    AdminUI --&gt;|\"Request with&lt;br/&gt;OpenShift Token\"| Gateway\n    Gateway --&gt;|\"/maas-api path\"| AuthPolicy\n    AuthPolicy --&gt;|\"Authenticated Request\"| API\n\n    API --&gt; TierMapping\n    API --&gt; TokenGen\n\n    TierMapping --&gt; ConfigMap\n    ConfigMap --&gt;|Maps Groups to Tiers| K8sGroups\n    TokenGen --&gt; FreeSA1\n    TokenGen --&gt; FreeSA2\n    TokenGen --&gt; PremiumSA1\n    TokenGen --&gt; EnterpriseSA1\n\n    K8sGroups --&gt;|Group Membership| TierMapping\n\n    style API fill:#1976d2,stroke:#333,stroke-width:2px,color:#fff\n    style ConfigMap fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style K8sGroups fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style FreeSA1 fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style FreeSA2 fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style PremiumSA1 fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style EnterpriseSA1 fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff</code></pre> <p>Key Features:</p> <ul> <li>Tier-to-Group Mapping: Uses ConfigMap in the same namespace as MaaS API to map Kubernetes groups to tiers</li> <li>Configurable Tiers: Out of the box, the MaaS Platform comes with three default tiers: free, premium, and enterprise. These tiers are configurable and can be extended to support more tiers as needed.</li> <li>Service Account Tokens: Generates tokens for the appropriate tier's service account based on user's group membership</li> <li>Future Enhancements: Planned improvements for more sophisticated token management and the ability to integrate with external identity providers.</li> </ul>"},{"location":"architecture/#inference-service-component-details","title":"Inference Service Component Details","text":"<p>Once a user has obtained their token through the MaaS API, they can use it to make inference requests to the Gateway API. RHCL's Application Connectivity Policies then validate the token and enforce access control and rate limiting policies:</p> <pre><code>graph TB\n    subgraph \"Client Layer\"\n        Client[Client Applications&lt;br/&gt;with Service Account Token]\n    end\n\n    subgraph \"Gateway Layer\"\n        GatewayAPI[**maas-default-gateway**&lt;br/&gt;maas.CLUSTER_DOMAIN]\n        Envoy[**Envoy Proxy**]\n    end\n\n    subgraph \"RHCL Policy Engine\"\n        Kuadrant[**Kuadrant**&lt;br/&gt;Policy Attachment]\n        Authorino[**Authorino**&lt;br/&gt;Authentication Service]\n        Limitador[**Limitador**&lt;br/&gt;Rate Limiting Service]\n    end\n\n    subgraph \"Policy Components\"\n        AuthPolicy[**AuthPolicy**&lt;br/&gt;gateway-auth-policy]\n        RateLimitPolicy[**RateLimitPolicy**&lt;br/&gt;gateway-rate-limits]\n        TokenRateLimitPolicy[**TokenRateLimitPolicy**&lt;br/&gt;gateway-token-rate-limits]\n    end\n\n    subgraph \"Model Access Control\"\n        RBAC[**Kubernetes RBAC**&lt;br/&gt;Service Account Permissions]\n        LLMInferenceService[**LLMInferenceService**&lt;br/&gt;Model Access Control]\n    end\n\n    subgraph \"Model Serving\"\n        RHOAI[**RHOAI Platform**]\n        Models[**LLM Models**&lt;br/&gt;Qwen, Granite, Llama]\n    end\n\n    subgraph \"Observability\"\n        Prometheus[**Prometheus**&lt;br/&gt;Metrics Collection]\n    end\n\n    Client --&gt;|Inference Request + Service Account Token| GatewayAPI\n    GatewayAPI --&gt; Envoy\n\n    Envoy --&gt; Kuadrant\n    Kuadrant --&gt; Authorino\n    Kuadrant --&gt; Limitador\n\n    Authorino --&gt; AuthPolicy\n    Limitador --&gt; RateLimitPolicy\n    Limitador --&gt; TokenRateLimitPolicy\n\n    Envoy --&gt;|Check Model Access| RBAC\n    RBAC --&gt; LLMInferenceService\n    LLMInferenceService --&gt;|POST Permission Check| RHOAI\n    RHOAI --&gt; Models\n\n    Limitador --&gt;|Usage Metrics| Prometheus\n\n    style GatewayAPI fill:#7b1fa2,stroke:#333,stroke-width:2px,color:#fff\n    style Kuadrant fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style Authorino fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style Limitador fill:#f57c00,stroke:#333,stroke-width:2px,color:#fff\n    style AuthPolicy fill:#d32f2f,stroke:#333,stroke-width:2px,color:#fff\n    style RateLimitPolicy fill:#d32f2f,stroke:#333,stroke-width:2px,color:#fff\n    style TokenRateLimitPolicy fill:#d32f2f,stroke:#333,stroke-width:2px,color:#fff\n    style RBAC fill:#d32f2f,stroke:#333,stroke-width:2px,color:#fff\n    style LLMInferenceService fill:#d32f2f,stroke:#333,stroke-width:2px,color:#fff\n    style RHOAI fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style Models fill:#388e3c,stroke:#333,stroke-width:2px,color:#fff\n    style Prometheus fill:#1976d2,stroke:#333,stroke-width:2px,color:#fff</code></pre> <p>Policy Engine Flow:</p> <ol> <li>User Request: A user makes an inference request to the Gateway API with a valid token.</li> <li>Service Account Authentication: Authorino validates service account tokens using gateway-auth-policy</li> <li>Rate Limiting: Limitador enforces usage quotas per tier/user using gateway-rate-limits and gateway-token-rate-limits</li> <li>Model Access Control: RBAC checks if service account has POST access to the specific LLMInferenceService</li> <li>Request Forwarding: Only requests with proper model access are forwarded to RHOAI</li> <li>Metrics Collection: Limitador sends usage data to Prometheus for observability dashboards</li> </ol>"},{"location":"architecture/#component-flows","title":"\ud83d\udd04 Component Flows","text":""},{"location":"architecture/#1-token-retrieval-flow-maas-api","title":"1. Token Retrieval Flow (MaaS API)","text":"<p>The MaaS API generates service account tokens based on user group membership and tier configuration:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Gateway as Gateway API\n    participant Authorino\n    participant MaaS as MaaS API\n    participant TierMapper as Tier Mapper\n    participant K8s as Kubernetes API\n\n    User-&gt;&gt;Gateway: POST /maas-api/v1/tokens&lt;br/&gt;Authorization: Bearer {openshift-token}\n    Gateway-&gt;&gt;Authorino: Enforce MaaS API AuthPolicy\n    Authorino-&gt;&gt;K8s: TokenReview (validate OpenShift token)\n    K8s--&gt;&gt;Authorino: User identity (username, groups)\n    Authorino-&gt;&gt;Gateway: Authenticated\n    Gateway-&gt;&gt;MaaS: Forward request with user context\n\n    Note over MaaS,TierMapper: Determine User Tier\n    MaaS-&gt;&gt;TierMapper: GetTierForGroups(user.groups)\n    TierMapper-&gt;&gt;K8s: Get ConfigMap(tier-to-group-mapping)\n    K8s--&gt;&gt;TierMapper: Tier configuration\n    TierMapper--&gt;&gt;MaaS: User tier (e.g., \"premium\")\n\n    Note over MaaS,K8s: Ensure Tier Resources\n    MaaS-&gt;&gt;K8s: Create Namespace({instance}-tier-{tier}) if needed\n    MaaS-&gt;&gt;K8s: Create ServiceAccount({username-hash}) if needed\n\n    Note over MaaS,K8s: Generate Token\n    MaaS-&gt;&gt;K8s: CreateToken(namespace, SA name, TTL)\n    K8s--&gt;&gt;MaaS: TokenRequest with token and expiration\n\n    MaaS--&gt;&gt;User: {&lt;br/&gt;  \"token\": \"...\",&lt;br/&gt;  \"expiration\": \"4h\",&lt;br/&gt;  \"expiresAt\": 1234567890&lt;br/&gt;}</code></pre>"},{"location":"architecture/#3-model-inference-flow","title":"3. Model Inference Flow","text":"<p>The inference flow routes validated requests to RHOAI models:</p> <p>The Gateway API and RHCL components validate service account tokens and enforce policies:</p> <pre><code>sequenceDiagram\n    participant Client\n    participant GatewayAPI\n    participant Kuadrant\n    participant Authorino\n    participant Limitador\n    participant AuthPolicy\n    participant RateLimitPolicy\n    participant LLMInferenceService\n\n    Client-&gt;&gt;GatewayAPI: Inference Request + Service Account Token\n    GatewayAPI-&gt;&gt;Kuadrant: Applying Policies\n    Kuadrant-&gt;&gt;Authorino: Validate Service Account Token\n    Authorino-&gt;&gt;AuthPolicy: Check Token Validity\n    AuthPolicy--&gt;&gt;Authorino: Token Valid + Tier Info\n    Authorino--&gt;&gt;Kuadrant: Authentication Success\n    Kuadrant-&gt;&gt;Limitador: Check Rate Limits\n    Limitador-&gt;&gt;RateLimitPolicy: Apply Tier-based Limits\n    RateLimitPolicy--&gt;&gt;Limitador: Rate Limit Status\n    Limitador--&gt;&gt;Kuadrant: Rate Check Result\n    Kuadrant--&gt;&gt;GatewayAPI: Policy Decision (Allow/Deny)\n    GatewayAPI -&gt;&gt; LLMInferenceService: Forward Request\n    LLMInferenceService--&gt;&gt;Client: Response</code></pre>"},{"location":"quickstart/","title":"Installation Guide","text":"<p>This guide provides quickstart instructions for deploying the MaaS Platform infrastructure.</p> <p>Note</p> <p>For more detailed instructions, please refer to Installation under the Administrator Guide.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>OpenShift cluster (4.19.9+) with kubectl/oc access<ul> <li>Recommended 16 vCPUs, 32GB RAM, 100GB storage</li> </ul> </li> <li>ODH/RHOAI requirements:<ul> <li>RHOAI 3.0 +</li> <li>ODH 3.0 +</li> </ul> </li> <li>RHCL requirements (Note: This can be installed automatically by the script below):<ul> <li>RHCL 1.2 +</li> </ul> </li> <li>Cluster admin or equivalent permissions</li> <li>Required tools:<ul> <li><code>oc</code> (OpenShift CLI)</li> <li><code>kubectl</code></li> <li><code>jq</code></li> <li><code>kustomize</code> (v5.7.0+)</li> </ul> </li> </ul>"},{"location":"quickstart/#quick-start","title":"Quick Start","text":""},{"location":"quickstart/#automated-openshift-deployment-recommended","title":"Automated OpenShift Deployment (Recommended)","text":"<p>For OpenShift clusters, use the automated deployment script:</p> <pre><code>export MAAS_REF=\"main\"\n./deployment/scripts/deploy-rhoai-stable.sh\n</code></pre>"},{"location":"quickstart/#verify-deployment","title":"Verify Deployment","text":"<p>The deployment script creates the following core resources:</p> <ul> <li>Gateway: <code>maas-default-gateway</code> in <code>openshift-ingress</code> namespace</li> <li>HTTPRoutes: <code>maas-api-route</code> in the <code>openshift-ingress</code> namespace</li> <li>Policies: <code>AuthPolicy</code>, <code>TokenRateLimitPolicy</code>, <code>RateLimitPolicy</code>, <code>TelemetryPolicy</code></li> <li>MaaS API: Deployment and service in <code>maas-api</code> namespace</li> <li>Operators: Cert-manager, LWS, Red Hat Connectivity Link and Red Hat OpenShift AI.</li> </ul> <p>Check deployment status:</p> <pre><code># Check all namespaces\nkubectl get ns | grep -E \"maas-api|kuadrant-system|kserve|opendatahub|redhat-ods-applications|llm\"\n\n# Check Gateway status\nkubectl get gateway -n openshift-ingress maas-default-gateway\n\n# Check policies\nkubectl get authpolicy -A\nkubectl get tokenratelimitpolicy -A\nkubectl get ratelimitpolicy -A\n\n# Check MaaS API\nkubectl get pods -n maas-api\nkubectl get svc -n maas-api\n\n# Check Kuadrant operators\nkubectl get pods -n kuadrant-system\n\n# Check KServe (if deployed)\nkubectl get pods -n kserve\nkubectl get pods -n opendatahub\nkubectl get pods -n redhat-ods-applications\n</code></pre>"},{"location":"quickstart/#model-setup-optional","title":"Model Setup (Optional)","text":""},{"location":"quickstart/#deploy-sample-models-optional","title":"Deploy Sample Models (Optional)","text":""},{"location":"quickstart/#simulator-model-cpu","title":"Simulator Model (CPU)","text":"<pre><code>PROJECT_DIR=$(git rev-parse --show-toplevel)\nkustomize build ${PROJECT_DIR}/docs/samples/models/simulator/ | kubectl apply -f -\n</code></pre>"},{"location":"quickstart/#facebook-opt-125m-model-cpu","title":"Facebook OPT-125M Model (CPU)","text":"<pre><code>PROJECT_DIR=$(git rev-parse --show-toplevel)\nkustomize build ${PROJECT_DIR}/docs/samples/models/facebook-opt-125m-cpu/ | kubectl apply -f -\n</code></pre>"},{"location":"quickstart/#qwen3-model-gpu-required","title":"Qwen3 Model (GPU Required)","text":"<p>Warning</p> <p>This model requires GPU nodes with <code>nvidia.com/gpu</code> resources available in your cluster.</p> <pre><code>PROJECT_DIR=$(git rev-parse --show-toplevel)\nkustomize build ${PROJECT_DIR}/docs/samples/models/qwen3/ | kubectl apply -f -\n</code></pre>"},{"location":"quickstart/#verify-model-deployment","title":"Verify Model Deployment","text":"<pre><code># Check LLMInferenceService status\nkubectl get llminferenceservices -n llm\n\n# Check pods\nkubectl get pods -n llm\n</code></pre>"},{"location":"quickstart/#update-existing-models-optional","title":"Update Existing Models (Optional)","text":"<p>To update an existing model, modify the <code>LLMInferenceService</code> to use the newly created <code>maas-default-gateway</code> gateway.</p> <pre><code>kubectl patch llminferenceservice my-production-model -n llm --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/gateway/refs/-\",\n    \"value\": {\n      \"name\": \"maas-default-gateway\",\n      \"namespace\": \"openshift-ingress\"\n    }\n  }\n]'\n</code></pre> <pre><code>apiVersion: serving.kserve.io/v1alpha1\nkind: LLMInferenceService\nmetadata:\n  name: my-production-model\nspec:\n  gateway:\n    refs:\n      - name: maas-default-gateway\n        namespace: openshift-ingress\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to Validation to test and verify your deployment.</p>"},{"location":"advanced-administration/limitador-persistence/","title":"Persisting Limitador Metric Counts","text":"<p>By default, Limitador stores its rate-limiting counters in memory. This provides high performance but has a significant drawback: if a Limitador pod restarts, scales down, or is rescheduled, all hit counts are lost.</p> <p>For persistent, production-ready rate limiting where counts are maintained across pod lifecycles, you must configure Limitador to use an external Redis backend.</p> <p>Warning</p> <p>Production Considerations: The basic Redis setup script provided in this document is intended for local development and validation only. For production deployments, follow the official Red Hat documentation for proper Redis configuration and high availability.</p>"},{"location":"advanced-administration/limitador-persistence/#table-of-contents","title":"Table of Contents","text":"<p>. Requirements for Persistent Counts . Example Limitador CR Configuration . Local Validation Script . How to Validate Persistence . Related Documentation</p>"},{"location":"advanced-administration/limitador-persistence/#requirements-for-persistent-counts","title":"Requirements for Persistent Counts","text":"<p>To enable persistence, two conditions must be met:</p> <p>. A Running Redis Instance: A Redis instance must be deployed and network-accessible from within the Kubernetes cluster.</p> <p>. Limitador Custom Resource (CR) Configuration: The Limitador CR that manages your deployment must be updated to point to the running Redis instance by specifying the storage configuration in its spec.</p>"},{"location":"advanced-administration/limitador-persistence/#example-limitador-cr-configuration","title":"Example Limitador CR Configuration","text":"<p>To configure Limitador to use Redis for persistent storage, you need to:</p> <p>. Create a Kubernetes Secret containing the Redis connection URL:</p> <pre><code>kubectl create secret generic redis-config \\\n  --from-literal=URL=redis://redis-service.redis-limitador.svc:6379 \\\n  --namespace=&lt;your-limitador-namespace&gt;\n</code></pre> <p>. Update your Limitador CR to reference the secret:</p> <pre><code>apiVersion: limitador.kuadrant.io/v1alpha1\nkind: Limitador\nmetadata:\n  name: limitador\nspec:\n  storage:\n    redis:\n      configSecretRef:\n        name: redis-config\n</code></pre> <p>Edit your existing Limitador CR:</p> <pre><code>kubectl edit limitador &lt;your-instance-name&gt; -n &lt;your-limitador-namespace&gt;\n</code></pre> <p>For detailed, official instructions on production Redis setup, refer to the Red Hat documentation:</p> <ul> <li>Red Hat Connectivity Link - Configure Redis</li> </ul>"},{"location":"advanced-administration/limitador-persistence/#local-validation-script-basic-dev-only-redis","title":"Local Validation Script (Basic Dev-only Redis)","text":"<p>A basic Redis setup script is provided for local development and validation. This script deploys a non-production Redis instance.</p> <p>Script Location: <code>deployment/scripts/setup-redis.sh</code></p>"},{"location":"advanced-administration/limitador-persistence/#namespace-selection","title":"Namespace Selection","text":"<p>The script uses a simple namespace selection logic:</p> <ul> <li><code>NAMESPACE</code> environment variable (if set)</li> <li>Default: <code>redis-limitador</code> (created automatically if it doesn't exist)</li> </ul> <p>This opinionated default simplifies troubleshooting and ensures consistent deployments.</p>"},{"location":"advanced-administration/limitador-persistence/#usage","title":"Usage","text":"<pre><code># Make the script executable\nchmod +x deployment/scripts/setup-redis.sh\n\n# Run with default namespace (redis-limitador)\n./deployment/scripts/setup-redis.sh\n\n# Or override with environment variable\nNAMESPACE=my-namespace ./deployment/scripts/setup-redis.sh\n</code></pre> <p>The script will:</p> <ul> <li>Create the namespace if it doesn't exist (for default <code>redis-limitador</code> namespace)</li> <li>Deploy a Redis Deployment and Service</li> <li>Wait for Redis to be ready</li> <li>Output instructions for creating a Secret and configuring your Limitador CR</li> </ul> <p>Note</p> <p>Single Source of Truth: The script content is maintained only in <code>deployment/scripts/setup-redis.sh</code>. Any updates to the script are automatically reflected when users download and run it.</p>"},{"location":"advanced-administration/limitador-persistence/#how-to-validate-persistence","title":"How to Validate Persistence","text":"<p>. Run the script: <code>./deployment/scripts/setup-redis.sh</code></p> <p>This will deploy Redis to the <code>redis-limitador</code> namespace by default (or use your <code>NAMESPACE</code> env var).</p> <p>. Follow the output instructions to create the Secret and configure your Limitador CR with the Redis storage configuration.</p> <p>. Send traffic against a rate-limited route until you have a non-zero hit count.</p> <p>You can verify metrics in Prometheus:</p> <pre><code># Port-forward to Prometheus (adjust namespace as needed)\nkubectl port-forward -n monitoring svc/prometheus-k8s 9090:9091\n\n# Query for authorized_hits metric\n# Open http://localhost:9090 and search for: authorized_hits\n</code></pre> <p>. Find your Limitador pod:</p> <pre><code>kubectl get pods -l app=limitador\n</code></pre> <p>. Delete the pod to force a restart:</p> <pre><code>kubectl delete pod &lt;limitador-pod-name&gt;\n</code></pre> <p>. Wait for the new pod to become Running:</p> <pre><code>kubectl get pods -l app=limitador -w\n</code></pre> <p>. Send another request to the same route. You will see that the metric count continues from its previous value instead of resetting to 1.</p>"},{"location":"advanced-administration/limitador-persistence/#related-documentation","title":"Related Documentation","text":"<ul> <li>Red Hat Connectivity Link - Configure Redis - Official Red Hat documentation for production Redis setup</li> </ul>"},{"location":"advanced-administration/observability/","title":"Observability","text":"<p>This document covers the observability stack for the MaaS Platform, including metrics collection, monitoring, and visualization.</p> <p>Important</p> <p>User Workload Monitoring must be enabled in order to collect metrics.</p> <p>Add <code>enableUserWorkload: true</code> to the <code>cluster-monitoring-config</code> in the <code>openshift-monitoring</code> namespace</p>"},{"location":"advanced-administration/observability/#overview","title":"Overview","text":"<p>As part of Dev Preview MaaS Platform includes a basic observability stack that provides insights into system performance, usage patterns, and operational health. The observability stack consists of:</p> <p>Note</p> <p>The observability stack will be enhanced in the future.</p> <ul> <li>Limitador: Rate limiting service that exposes metrics</li> <li>Prometheus: Metrics collection and storage</li> <li>Grafana: Metrics visualization and dashboards</li> <li>Future: Migration to Perses for enhanced dashboard management</li> </ul>"},{"location":"advanced-administration/observability/#metrics-collection","title":"Metrics Collection","text":""},{"location":"advanced-administration/observability/#limitador-metrics","title":"Limitador Metrics","text":"<p>Limitador exposes several key metrics that are collected through a ServiceMonitor by Prometheus:</p>"},{"location":"advanced-administration/observability/#rate-limiting-metrics","title":"Rate Limiting Metrics","text":"<ul> <li><code>limitador_ratelimit_requests_total</code>: Total number of rate limit requests</li> <li><code>limitador_ratelimit_allowed_total</code>: Number of requests allowed</li> <li><code>limitador_ratelimit_denied_total</code>: Number of requests denied</li> <li><code>limitador_ratelimit_errors_total</code>: Number of rate limiting errors</li> </ul>"},{"location":"advanced-administration/observability/#performance-metrics","title":"Performance Metrics","text":"<ul> <li><code>limitador_ratelimit_duration_seconds</code>: Duration of rate limit checks</li> <li><code>limitador_ratelimit_active_connections</code>: Number of active connections</li> <li><code>limitador_ratelimit_cache_hits_total</code>: Cache hit rate</li> <li><code>limitador_ratelimit_cache_misses_total</code>: Cache miss rate</li> </ul>"},{"location":"advanced-administration/observability/#tier-based-metrics","title":"Tier-Based Metrics","text":"<ul> <li><code>limitador_ratelimit_tier_requests_total</code>: Requests per tier</li> <li><code>limitador_ratelimit_tier_allowed_total</code>: Allowed requests per tier</li> <li><code>limitador_ratelimit_tier_denied_total</code>: Denied requests per tier</li> </ul>"},{"location":"advanced-administration/observability/#servicemonitor-configuration","title":"ServiceMonitor Configuration","text":"<p>For automatic discovery of services, use ServiceMonitor resources:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: limitador-monitor\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:\n      app: limitador\n  endpoints:\n  - port: metrics\n    interval: 10s\n    path: /metrics\n</code></pre>"},{"location":"advanced-administration/observability/#high-availability-for-maas-metrics","title":"High Availability for MaaS Metrics","text":"<p>For production deployments where metric persistence across pod restarts and scaling events is critical, you should configure Limitador to use Redis as a backend storage solution.</p>"},{"location":"advanced-administration/observability/#why-high-availability-matters","title":"Why High Availability Matters","text":"<p>By default, Limitador stores rate-limiting counters in memory, which means:</p> <ul> <li>All hit counts are lost when pods restart</li> <li>Metrics reset when pods are rescheduled or scaled down</li> <li>No persistence across cluster maintenance or updates</li> </ul>"},{"location":"advanced-administration/observability/#setting-up-persistent-metrics","title":"Setting Up Persistent Metrics","text":"<p>To enable persistent metric counts, refer to the detailed guide:</p> <p>Configuring Redis storage for rate limiting</p> <p>This Red Hat documentation provides:</p> <ul> <li>Step-by-step Redis configuration for OpenShift</li> <li>Secret management for Redis credentials</li> <li>Limitador custom resource updates</li> <li>Production-ready setup instructions</li> </ul> <p>For local development and testing, you can also use our Limitador Persistence guide which includes a basic Redis setup script that works with any Kubernetes cluster.</p>"},{"location":"advanced-administration/observability/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"advanced-administration/observability/#maas-platform-overview-dashboard","title":"MaaS Platform Overview Dashboard","text":"<p>We are providing a basic dashboard for the MaaS Platform that can be used to get a quick overview of the system. Its definition can be found and imported from the following  link: maas-token-metrics-dashboard.json</p> <p>See more detailed description of the Grafana Dashboard in its README of the  repository.</p>"},{"location":"configuration-and-management/model-setup/","title":"Model Setup Guide","text":"<p>This guide explains how to configure <code>LLMInferenceService</code> resources to be picked up by the MaaS platform for authentication, rate limiting, and token-based consumption tracking.</p>"},{"location":"configuration-and-management/model-setup/#gateway-architecture","title":"Gateway Architecture","text":"<p>The MaaS platform uses a segregated gateway approach, where models explicitly opt-in to MaaS capabilities by referencing the <code>maas-default-gateway</code>. This provides flexibility and isolation between different model deployment scenarios.</p> <pre><code>graph TB\n    subgraph cluster[\"OpenShift/Kubernetes Cluster\"]\n        subgraph gateways[\"Gateway Layer\"]\n            defaultGW[\"&lt;b&gt;Default Gateway&lt;/b&gt;&lt;br/&gt;(ODH/KServe)&lt;br/&gt;&lt;br/&gt;\u2713 Existing auth model&lt;br/&gt;\u2713 No rate limits&lt;br/&gt;\"]\n            maasGW[\"&lt;b&gt;MaaS Gateway&lt;/b&gt;&lt;br/&gt;(maas-default-gateway)&lt;br/&gt;&lt;br/&gt;\u2713 Token authentication&lt;br/&gt;\u2713 Tier-based rate limits&lt;br/&gt;\u2713 Token consumption \"]\n        end\n\n        subgraph models[\"Model Deployments\"]\n            standardModel[\"LLMInferenceService&lt;br/&gt;(Standard)&lt;br/&gt;&lt;br/&gt;spec:&lt;br/&gt;  model: ...&lt;br/&gt;  # Managed default Gateway instance\"]\n            maasModel[\"LLMInferenceService&lt;br/&gt;(MaaS-enabled)&lt;br/&gt;&lt;br/&gt;spec:&lt;br/&gt;  model: ...&lt;br/&gt;  router:&lt;br/&gt;    gateway:&lt;br/&gt;      refs:&lt;br/&gt;        - name: maas-default-gateway\"]\n        end\n\n        defaultGW -.-&gt;|\"Routes to\"| standardModel\n        maasGW ==&gt;|\"Routes to\"| maasModel\n    end\n\n    users[\"Users/Clients\"] --&gt;|\"Default ODH auth\"| defaultGW\n    apiUsers[\"API Clients\"] --&gt;|\"Bearer token\"| maasGW\n\n    style defaultGW fill:#e1f5ff\n    style maasGW fill:#fff4e6\n    style standardModel fill:#f5f5f5\n    style maasModel fill:#fff9e6\n    style cluster fill:#fafafa\n    style gateways fill:#ffffff\n    style models fill:#ffffff</code></pre> <p>Note</p> <p>The <code>maas-default-gateway</code> is created automatically during MaaS platform installation. You don't need to create it manually.</p>"},{"location":"configuration-and-management/model-setup/#benefits","title":"Benefits","text":"<p>. Flexibility: Different models can have different security and access requirements . Progressive Adoption: Teams can adopt MaaS features incrementally . Production Control: Production models get full policy enforcement if needed . Multi-Tenancy: Different teams can use different gateways in the same cluster . Blast Radius Containment: Issues with one gateway don't affect the other</p>"},{"location":"configuration-and-management/model-setup/#prerequisites","title":"Prerequisites","text":"<p>Before configuring a model for MaaS, ensure you have:</p> <ul> <li>MaaS platform installed with <code>maas-default-gateway</code> deployed</li> <li>LLMInferenceService resource created or planned</li> <li>Cluster admin or equivalent permissions to modify <code>LLMInferenceService</code> resources</li> </ul>"},{"location":"configuration-and-management/model-setup/#configuring-models-for-maas","title":"Configuring Models for MaaS","text":"<p>To make your model available through the MaaS platform, you need to:</p> <ol> <li>Reference the maas-default-gateway in your <code>LLMInferenceService</code> spec</li> <li>Add the tier annotation to enable automatic RBAC setup</li> </ol>"},{"location":"configuration-and-management/model-setup/#step-1-add-gateway-reference","title":"Step 1: Add Gateway Reference","text":"<p>Configure your <code>LLMInferenceService</code> to use the <code>maas-default-gateway</code> by adding the gateway reference in the <code>router</code> section:</p> <pre><code>apiVersion: serving.kserve.io/v1alpha1\nkind: LLMInferenceService\nmetadata:\n  name: my-production-model\n  namespace: llm\nspec:\n  model:\n    uri: hf://Qwen/Qwen3-0.6B\n    name: Qwen/Qwen3-0.6B\n  replicas: 1\n\n  # Connect to MaaS-enabled gateway\n  router:\n    route: { }\n    gateway:\n      refs:\n        - name: maas-default-gateway\n          namespace: openshift-ingress\n\n  template:\n    # ... container configuration ...\n</code></pre> <p>Key Points:</p> <ul> <li>The <code>router.gateway.refs</code> field specifies which gateway to use</li> <li>Use <code>name: maas-default-gateway</code> and <code>namespace: openshift-ingress</code></li> <li>Without this specification, the model uses the default KServe gateway and is not subject to MaaS policies</li> </ul>"},{"location":"configuration-and-management/model-setup/#step-2-configure-tier-access-with-annotation","title":"Step 2: Configure Tier Access with Annotation","text":"<p>Add the <code>alpha.maas.opendatahub.io/tiers</code> annotation to enable automatic RBAC setup for tier-based access:</p> <pre><code>apiVersion: serving.kserve.io/v1alpha1\nkind: LLMInferenceService\nmetadata:\n  name: my-production-model\n  namespace: llm\n  annotations:\n    alpha.maas.opendatahub.io/tiers: '[]'\nspec:\n  # ... rest of spec ...\n</code></pre> <p>Annotation Values:</p> <ul> <li>Empty list <code>[]</code>: Grants access to all tiers (recommended for most models)</li> <li>List of tier names: Grants access to specific tiers only</li> <li>Example: <code>'[\"premium\",\"enterprise\"]'</code> - only premium and enterprise tiers can access</li> <li>Missing annotation: No tiers have access by default (model won't be accessible via MaaS)</li> </ul> <p>Examples:</p> <p>Allow all tiers:</p> <pre><code>annotations:\n  alpha.maas.opendatahub.io/tiers: '[]'\n</code></pre> <p>Allow specific tiers:</p> <pre><code>annotations:\n  alpha.maas.opendatahub.io/tiers: '[\"premium\",\"enterprise\"]'\n</code></pre>"},{"location":"configuration-and-management/model-setup/#what-the-annotation-does","title":"What the Annotation Does","text":"<p>This annotation automatically creates the necessary RBAC resources (Roles and RoleBindings) that allow tier-specific service accounts to POST to your <code>LLMInferenceService</code>. The ODH Controller handles this automatically when the annotation is present.</p> <p>Behind the scenes, it creates:</p> <ul> <li>Role: Grants <code>POST</code> permission on <code>llminferenceservices</code> resource</li> <li>RoleBinding: Binds tier service account groups (e.g., <code>system:serviceaccounts:maas-default-gateway-tier-premium</code>) to the role</li> </ul>"},{"location":"configuration-and-management/model-setup/#complete-example","title":"Complete Example","text":"<p>Here's a complete example of a MaaS-enabled model:</p> <pre><code>apiVersion: serving.kserve.io/v1alpha1\nkind: LLMInferenceService\nmetadata:\n  name: qwen3-model\n  namespace: llm\n  annotations:\n    alpha.maas.opendatahub.io/tiers: '[]'\nspec:\n  model:\n    uri: hf://Qwen/Qwen3-0.6B\n    name: Qwen/Qwen3-0.6B\n  replicas: 1\n  router:\n    route: { }\n    gateway:\n      refs:\n        - name: maas-default-gateway\n          namespace: openshift-ingress\n  template:\n    containers:\n      - name: main\n        image: \"vllm/vllm-openai:latest\"\n        resources:\n          limits:\n            nvidia.com/gpu: \"1\"\n            memory: 12Gi\n          requests:\n            nvidia.com/gpu: \"1\"\n            memory: 8Gi\n</code></pre>"},{"location":"configuration-and-management/model-setup/#updating-existing-models","title":"Updating Existing Models","text":"<p>To convert an existing model to use MaaS:</p>"},{"location":"configuration-and-management/model-setup/#method-1-patch-the-model","title":"Method 1: Patch the Model","text":"<pre><code>kubectl patch llminferenceservice my-production-model -n llm --type='json' -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/router/gateway/refs/-\",\n    \"value\": {\n      \"name\": \"maas-default-gateway\",\n      \"namespace\": \"openshift-ingress\"\n    }\n  }\n]'\n\n# Add the tier annotation\nkubectl annotate llminferenceservice my-production-model -n llm \\\n  alpha.maas.opendatahub.io/tiers='[]' \\\n  --overwrite\n</code></pre>"},{"location":"configuration-and-management/model-setup/#method-2-edit-the-resource","title":"Method 2: Edit the Resource","text":"<pre><code>kubectl edit llminferenceservice my-production-model -n llm\n</code></pre> <p>Then add:</p> <ul> <li>Gateway reference in <code>spec.router.gateway.refs</code></li> <li>Annotation <code>alpha.maas.opendatahub.io/tiers</code> in <code>metadata.annotations</code></li> </ul>"},{"location":"configuration-and-management/model-setup/#verification","title":"Verification","text":"<p>After configuring your model, verify it's accessible through MaaS:</p> <p>1. Check the model appears in the models list:</p> <pre><code># Get your MaaS token first, then:\ncurl -sSk ${HOST}/maas-api/v1/models \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $TOKEN\" | jq .\n</code></pre> <p>2. Verify the model status:</p> <pre><code>kubectl get llminferenceservice my-production-model -n llm\n</code></pre> <p>3. Check RBAC was created (if using tier annotation):</p> <pre><code>kubectl get roles,rolebindings -n llm | grep my-production-model\n</code></pre> <p>4. Test inference request:</p> <pre><code># Use the MODEL_URL from the models list\ncurl -sSk -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\": \"my-production-model\", \"prompt\": \"Hello\", \"max_tokens\": 50}' \\\n  \"${MODEL_URL}\"\n</code></pre>"},{"location":"configuration-and-management/model-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration-and-management/model-setup/#model-not-appearing-in-maas-apiv1models","title":"Model Not Appearing in /maas-api/v1/models","text":"<ul> <li>Verify the gateway reference is correct: <code>name: maas-default-gateway</code>, <code>namespace: openshift-ingress</code></li> <li>Check that the model's status shows it's ready</li> <li>Ensure the model namespace is accessible (some configurations may restrict discovery)</li> </ul>"},{"location":"configuration-and-management/model-setup/#401-unauthorized-when-accessing-model","title":"401 Unauthorized When Accessing Model","text":"<ul> <li>Verify the tier annotation is set: <code>alpha.maas.opendatahub.io/tiers: '[]'</code> (or specific tiers)</li> <li>Check that your token's tier matches one of the tiers allowed in the annotation</li> <li>Verify RBAC resources were created: <code>kubectl get roles,rolebindings -n &lt;model-namespace&gt;</code></li> </ul>"},{"location":"configuration-and-management/model-setup/#403-forbidden-when-accessing-model","title":"403 Forbidden When Accessing Model","text":"<ul> <li>Ensure the tier annotation includes your tier</li> <li>Check that RBAC was properly created for your tier</li> <li>Verify the service account in your token has the correct tier namespace</li> </ul>"},{"location":"configuration-and-management/model-setup/#references","title":"References","text":"<ul> <li>Tier Management - Learn about configuring tier access</li> <li>Tier Configuration - Detailed tier setup instructions</li> <li>Architecture Overview - Understand the overall MaaS architecture</li> <li>KServe LLMInferenceService Documentation - Official KServe documentation</li> </ul>"},{"location":"configuration-and-management/tier-concepts/","title":"Tier Concepts","text":"<p>This section provides reference information about how the tier system works.</p>"},{"location":"configuration-and-management/tier-concepts/#tier-membership-mapping","title":"Tier Membership Mapping","text":"<p>MaaS and Kubernetes administrators can defined the subscription levels using the <code>tier-to-group-mapping</code> ConfigMap in the <code>maas-api</code> namespace:</p> <p>tier-to-group-mapping.yaml ConfigMap example:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: tier-to-group-mapping\n  namespace: maas-api\ndata:\n  tiers: |\n    - name: free\n      description: Free tier for basic users\n      level: 1\n      groups:\n      - system:authenticated\n    - name: premium\n      description: Premium tier\n      level: 10\n      groups:\n      - premium-users\n    - name: enterprise\n      description: Enterprise tier\n      level: 20\n      groups:\n      - enterprise-users\n</code></pre>"},{"location":"configuration-and-management/tier-concepts/#configmap-field-breakdown","title":"ConfigMap Field Breakdown","text":"Field Purpose Default Value name The tier identifier used throughout the system. Must be unique and matches tier names in rate limit policies. <code>free</code>, <code>premium</code>, <code>enterprise</code> description Human-readable description of the tier's purpose and who it's intended for. Used for documentation and UI display. <code>Free tier for basic users</code>, <code>Enterprise tier for high-volume customers</code> level Numeric hierarchy for tier precedence. Higher numbers indicate higher tiers.  When a user belongs to multiple groups, the highest level tier is selected. <code>1</code> (lowest), <code>10</code> (medium), <code>20</code> (highest) groups Kubernetes groups whose members are assigned to this tier.  Users must be members of at least one group in the list to get this tier. <code>system:authenticated</code>, <code>premium-users</code>, <code>enterprise-users</code> <p>Important Notes:</p> <ul> <li>Users with multiple group memberships are assigned to the tier with the highest level number</li> <li>The <code>system:authenticated</code> group includes all authenticated users, commonly used for the free tier</li> <li>Group names must exist in your Kubernetes identity provider (LDAP, OIDC, etc.)</li> <li>Tier <code>name</code> values are case-sensitive and must match exactly with rate limit policy predicates</li> </ul>"},{"location":"configuration-and-management/tier-concepts/#tier-rate-limits-configuration","title":"Tier Rate Limits Configuration","text":"<p>MaaS and Kubernetes administrators can configure rate limits for each tier using the <code>RateLimitPolicy</code> custom resource.</p> <p>RateLimitPolicy.yaml example:</p> <pre><code>apiVersion: kuadrant.io/v1beta2\nkind: RateLimitPolicy\nmetadata:\n  name: model-rate-limits\n  namespace: llm\n</code></pre>"},{"location":"configuration-and-management/tier-concepts/#tier-namespaces","title":"Tier Namespaces","text":"<p>Each tier gets a dedicated namespace following the pattern <code>&lt;instance-name&gt;-tier-&lt;tier-name&gt;</code>:</p> <ul> <li><code>maas-default-gateway-tier-free</code></li> <li><code>maas-default-gateway-tier-premium</code></li> <li><code>maas-default-gateway-tier-enterprise</code></li> </ul>"},{"location":"configuration-and-management/tier-concepts/#tier-resolution-process","title":"Tier Resolution Process","text":"<ol> <li>User authenticates with JWT token</li> <li>Gateway extracts user groups from token</li> <li>MaaS API resolves tier based on group membership</li> <li>Tier information is cached for 5 minutes</li> <li>Access control and rate limiting are applied based on tier</li> </ol>"},{"location":"configuration-and-management/tier-configuration/","title":"Tier Configuration","text":"<p>This guide provides step-by-step instructions for configuring and managing tiers in the MaaS Platform.</p>"},{"location":"configuration-and-management/tier-configuration/#configuration-steps","title":"Configuration Steps","text":""},{"location":"configuration-and-management/tier-configuration/#1-configure-tier-mapping","title":"1. Configure Tier Mapping","text":"<p>Update <code>tier-to-group-mapping</code> ConfigMap:</p> <p>To add a new tier, save the current ConfigMap, modify it, and reapply:</p> <pre><code># 1. Edit ConfigMap (use example below as a guide)\nkubectl edit configmap tier-to-group-mapping -n maas-api\n\n# Example: Add this tier entry to the end of the tiers list:\n#   - name: stier\n#     description: S tier user\n#     level: 99\n#     groups:\n#     - fox\n</code></pre> <p>Verify the updated ConfigMap:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: tier-to-group-mapping\n  namespace: maas-api\ndata:\n  tiers: |\n    - name: free\n      description: Free tier for basic users\n      level: 1\n      groups:\n      - system:authenticated\n    - name: premium\n      description: Premium tier\n      level: 10\n      groups:\n      - premium-users\n    - name: enterprise\n      description: Enterprise tier\n      level: 20\n      groups:\n      - enterprise-users\nEOF\n</code></pre> <p>Restart the MaaS API to pick up the new configuration:</p> <pre><code>kubectl rollout restart deployment/maas-api -n maas-api\n</code></pre> <p>Adding Users to Tiers</p> <p>To add a user to a tier, add them to the appropriate Kubernetes group. For example, to add a user to the <code>fox</code> group (which maps to the <code>stier</code> tier in this example):</p> <pre><code># Add a user to the fox group\nkubectl patch group fox -p '{\"users\": [\"username\"]}' --type merge\n</code></pre> <p>Replace <code>username</code> with the actual username. Users will automatically be assigned to the tier when they request a new token.</p>"},{"location":"configuration-and-management/tier-configuration/#2-configure-tier-access","title":"2. Configure Tier Access","text":"<p>Grant tier-specific access to models by annotating the <code>LLMInferenceService</code> resource with the <code>alpha.maas.opendatahub.io/tiers</code> annotation:</p> <pre><code>kubectl annotate llminferenceservice &lt;model-name&gt; -n llm \\\n  alpha.maas.opendatahub.io/tiers='[\"stier\",\"premium\",\"enterprise\"]' \\\n  --overwrite\n</code></pre> <p>Annotation Behavior:</p> <ul> <li>List of tier names: Grant access to specific tiers (e.g., <code>[\"stier\",\"premium\",\"enterprise\"]</code>)</li> <li>Empty list <code>[]</code>: Grant access to all tiers</li> <li>Missing annotation: No tiers have access by default</li> </ul> <p>Example - Grant access to stier and premium tiers:</p> <pre><code>kubectl annotate llminferenceservice qwen3 -n llm \\\n  alpha.maas.opendatahub.io/tiers='[\"stier\",\"premium\"]' \\\n  --overwrite\n</code></pre> <p>This annotation automatically sets up the necessary RBAC (Role and RoleBinding) for the specified tiers to access the model via MaaS tokens.</p> <p>Manual RBAC Setup</p> <p>For reference, here's what the automatic RBAC setup looks like behind the scenes if you need to configure access manually:</p> <pre><code>---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: model-post-access\n  namespace: &lt;model-namespace&gt;\nrules:\n  - apiGroups: [\"serving.kserve.io\"]\n    resources: [\"llminferenceservices\"]\n    verbs: [\"post\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: model-post-access-tier-binding\n  namespace: &lt;model-namespace&gt;\nsubjects:\n  - kind: Group\n    name: system:serviceaccounts:maas-default-gateway-tier-&lt;tier&gt;\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: model-post-access\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"configuration-and-management/tier-configuration/#3-configure-rate-limiting","title":"3. Configure Rate Limiting","text":"<p>Add tier-specific rate limits by patching the existing <code>gateway-token-rate-limits</code> TokenRateLimitPolicy:</p> <pre><code>kubectl patch tokenratelimitpolicy gateway-token-rate-limits -n openshift-ingress --type merge --patch-file=/dev/stdin &lt;&lt;'EOF'\nspec:\n  limits:\n    stier-user-tokens: # 1\n      rates:\n        - limit: 999 # 2\n          window: 1m # 3\n      when:\n        - predicate: auth.identity.tier == \"stier\" # 4\n      counters:\n        - expression: auth.identity.userid # 5\nEOF\n</code></pre> <p>Rate Limit Policy Configuration Explained:</p> <ol> <li>Tier definition - Each tier (free, premium, enterprise) gets its own configuration block (this is just a naming convention, it is not used for the actual tier resolution)</li> <li>Token limit - Maximum number of total tokens allowed per time window</li> <li>Time window - Duration after which the request counter resets</li> <li>Predicate condition - Determines when this tier's limits apply based on user authentication</li> <li>Counter expression - Tracks token consumption per user ID (globally)</li> </ol> <p>Important</p> <p>The predicate condition (not the Tier Definition) is used to determine when this tier's limits apply based on user authentication. It is a CEL expression that is evaluated by the Authorino policy engine.</p> <p>Validate the TokenRateLimitPolicy has been updated and enforced:</p> <pre><code># Delete the Kuadrant operator pod to trigger a re-sync\nkubectl delete pod -l control-plane=controller-manager -n kuadrant-system\n\n# Wait for the TokenRateLimitPolicy to be enforced\nkubectl wait --for=condition=Enforced=true tokenratelimitpolicy/gateway-token-rate-limits -n openshift-ingress --timeout=2m\n</code></pre>"},{"location":"configuration-and-management/tier-configuration/#4-validate-the-configuration","title":"4. Validate the Configuration","text":"<p>Configuration can be validated by logging in as a user belonging to the appropriate group and running through the manual validation steps in the deployment scripts documentation, or by using the automated validation script.</p> <pre><code># Validate the configuration with 20 requests and a max tokens limit of 500\n./deployment/scripts/validate-deployment.sh --rate-limit-requests 20 --max-tokens 500\n</code></pre> <p>Example Output:</p> <pre><code>\ud83d\udd0d Checking: Token information\n\u2139\ufe0f  Token subject: system:serviceaccount:maas-default-gateway-tier-stier:jland-78028f6d\n\u2705 PASS: User tier: stier &lt;--- Important\n\ud83d\udd0d Checking: Models endpoint\n\u2705 PASS: Models endpoint returns 200 OK\n...\n\ud83d\udd0d Checking: Rate limiting\n\u2139\ufe0f  Sending 20 rapid requests to test rate limiting...\n\u2705 PASS: Rate limiting is working (5 successful, 15 rate limited) &lt;--- Important\n</code></pre>"},{"location":"configuration-and-management/tier-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration-and-management/tier-configuration/#general-tips","title":"General Tips","text":"<p>Authentication errors (403/401): Check Authorino logs for detailed error messages:</p> <pre><code>kubectl logs -n openshift-ingress -l app.kubernetes.io/name=authorino --tail=50\n</code></pre> <p>Token retrieval issues: Check MaaS API logs during the token request:</p> <pre><code>kubectl logs -n maas-api -l app=maas-api --tail=50\n</code></pre> <p>Policy enforcement issues: Restart the Kuadrant operator to trigger policy re-sync:</p> <pre><code>kubectl delete pod -l control-plane=controller-manager -n kuadrant-system\n</code></pre>"},{"location":"configuration-and-management/tier-configuration/#common-issues","title":"Common Issues","text":""},{"location":"configuration-and-management/tier-configuration/#403-forbidden-not-authorized-unknown-reason","title":"403 Forbidden: \"not authorized: unknown reason\"","text":"<p>Possible Cause: Added new tier to ConfigMap but didn't update <code>gateway-token-rate-limits</code> TokenRateLimitPolicy.</p> <p>Fix: Validate/Update the TokenRateLimitPolicy as documented in Configure Rate Limiting, then restart the Kuadrant operator:</p> <pre><code>kubectl patch tokenratelimitpolicy gateway-token-rate-limits -n openshift-ingress --type merge --patch-file=/dev/stdin &lt;&lt;'EOF'\nspec:\n  limits:\n    &lt;tier-name&gt;-user-tokens:\n      rates:\n        - limit: 999\n          window: 1m\n      when:\n        - predicate: auth.identity.tier == \"&lt;tier-name&gt;\"\n      counters:\n        - expression: auth.identity.userid\nEOF\n\nkubectl delete pod -l control-plane=controller-manager -n kuadrant-system\n</code></pre>"},{"location":"configuration-and-management/tier-overview/","title":"Tier Management Overview","text":"<p>This guide explains how to configure and manage subscription tiers for the MaaS Platform. Tiers enable differentiated service levels with varying access permissions, rate limits, and quotas.</p>"},{"location":"configuration-and-management/tier-overview/#overview","title":"Overview","text":"<p>The tier system is driven by Kubernetes native objects and provides:</p> <ul> <li>Group-based access control: Users are assigned tiers based on their Kubernetes group membership</li> <li>Namespace-scoped RBAC: Each tier has its own namespace for permission management</li> <li>Dynamic tier resolution: User tiers are resolved on each request</li> <li>Per-model authorization: Access control is enforced at the model level</li> <li>Hierarchical precedence: Users with multiple group memberships get the highest tier</li> </ul>"},{"location":"configuration-and-management/tier-overview/#documentation-structure","title":"Documentation Structure","text":"<p>This tier management documentation is organized into three sections:</p> <ol> <li>Tier Overview (this document) - High-level overview of the tier system</li> <li>Tier Configuration - Step-by-step configuration guide</li> <li>Tier Concepts - Reference material explaining how the tier system works</li> </ol>"},{"location":"configuration-and-management/tier-overview/#quick-start","title":"Quick Start","text":"<p>To get started with tier management, see the Configuration Guide.</p> <p>For detailed information about how the tier system works internally, see the Tier Concepts documentation.</p>"},{"location":"configuration-and-management/token-management/","title":"Understanding Token Management","text":"<p>This guide explains the token-based authentication system used to access models in the tier-based access control system.  It covers how token issuance works, the underlying service account architecture, and token lifecycle management.</p> <p>Note</p> <p>Prerequisites: This document assumes you have already configured tiers, RBAC, and rate limits.  See Configuring Subscription Tiers for setup instructions.</p>"},{"location":"configuration-and-management/token-management/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>How Token Issuance Works</li> <li>Practical Usage</li> <li>Token Lifecycle Management</li> <li>Frequently Asked Questions (FAQ)</li> <li>Related Documentation</li> </ol>"},{"location":"configuration-and-management/token-management/#overview","title":"Overview","text":"<p>The platform uses a secure, token-based authentication system. Instead of using your primary OpenShift credentials to  access models directly, you first exchange them for a temporary, specialized access token. This approach provides several key benefits:</p> <ul> <li>Enhanced Security: Tokens are short-lived, reducing the risk of compromised credentials. They are also narrowly scoped for model access only.</li> <li>Tier-Based Access Control: The token you receive is automatically associated with your subscription tier (e.g., free, premium), ensuring you get the correct permissions and rate limits.</li> <li>Auditability: Every request made with a token is tied to a specific identity and can be audited.</li> <li>Kubernetes-Native Integration: The system leverages standard, Kubernetes authentication and authorization mechanisms.</li> </ul> <p>The process is simple:</p> <pre><code>You authenticate with OpenShift \u2192 Request a token from the API \u2192 Use that token to call models\n</code></pre>"},{"location":"configuration-and-management/token-management/#how-token-issuance-works","title":"How Token Issuance Works","text":"<p>When you request a token, you are essentially trading your long-term OpenShift identity for a short-term,  purpose-built identity in the form of a Kubernetes Service Account.</p>"},{"location":"configuration-and-management/token-management/#key-concepts","title":"Key Concepts","text":"<ul> <li>Tier Namespace: The platform maintains a separate Kubernetes namespace for each subscription tier (e.g., <code>...-tier-free</code>, <code>...-tier-premium</code>). These namespaces isolate users based on their access level. </li> <li>Service Account (SA): When you request a token for the first time, the system creates a Service Account that represents you inside your designated tier namespace. This SA inherits all the permissions assigned to that tier.</li> <li>Access Token: The token you receive is a standard JSON Web Token (JWT) that authenticates you as that specific Service Account. When you present this token to the gateway, the system knows your identity, your tier, and what permissions you have.</li> <li>Token Audience: The intended recipient of your token. This is validated during authentication and must match the gateway's configuration.</li> <li>Token Expiration: The time after which the token expires. Tokens are short-lived to reduce the risk of compromised credentials.</li> </ul>"},{"location":"configuration-and-management/token-management/#token-issuance-flow","title":"Token Issuance Flow","text":"<p>This diagram illustrates the process of obtaining a token.</p> <pre><code>sequenceDiagram\n    participant User as OpenShift User\n    participant MaaS as maas-api\n    participant K8s as Kubernetes API\n    participant TierNS as Tier Namespace&lt;br/&gt;(e.g., *-tier-premium)\n    participant Gateway\n    participant Model as Model Backend\n\n    Note over User,MaaS: Token Issuance\n    User-&gt;&gt;MaaS: 1. Authenticate with OpenShift token\n    MaaS-&gt;&gt;K8s: Validate token (TokenReview)\n    K8s--&gt;&gt;MaaS: username, groups\n    Note right of MaaS: Determine tier from&lt;br/&gt;tier-to-group-mapping\n    MaaS-&gt;&gt;K8s: Ensure tier namespace exists\n    K8s-&gt;&gt;TierNS: Create if needed\n    MaaS-&gt;&gt;TierNS: Create/get Service Account for user\n    TierNS--&gt;&gt;MaaS: SA ready\n    MaaS-&gt;&gt;K8s: Request SA token (TokenRequest)\n    K8s--&gt;&gt;MaaS: Issued token\n    MaaS--&gt;&gt;User: Return issued token\n\n    Note over User,Model: Model Access\n    User-&gt;&gt;Gateway: 3. Request with issued token\n    Gateway-&gt;&gt;K8s: Validate token (TokenReview)\n    Note right of K8s: Token from SA in&lt;br/&gt;tier namespace\n    K8s--&gt;&gt;Gateway: Valid, with groups\n    Note right of Gateway: Tier lookup,&lt;br/&gt;SAR check,&lt;br/&gt;Rate limits\n    Gateway-&gt;&gt;Model: 4. Authorized request\n    Model--&gt;&gt;Gateway: Response\n    Gateway--&gt;&gt;User: Response</code></pre>"},{"location":"configuration-and-management/token-management/#practical-usage","title":"Practical Usage","text":"<p>For step-by-step instructions on obtaining and using tokens to access models, including practical examples and troubleshooting, see the Self-Service Model Access Guide.</p> <p>That guide provides: - Complete walkthrough for getting your OpenShift token - How to request an access token from the API - Examples of making inference requests with your token - Troubleshooting common authentication issues</p>"},{"location":"configuration-and-management/token-management/#token-lifecycle-management","title":"Token Lifecycle Management","text":"<p>Access tokens are ephemeral and must be managed accordingly.</p>"},{"location":"configuration-and-management/token-management/#token-expiration","title":"Token Expiration","text":"<p>Tokens have a finite lifetime for security purposes:</p> <ul> <li>Default lifetime: 4 hours (configurable when requesting)</li> <li>Maximum lifetime: Determined by your Kubernetes cluster configuration</li> </ul> <p>When a token expires, any API request using it will fail with an <code>HTTP 401 Unauthorized error</code>.  To continue, you must request a new token using the process described above.</p> <p>Tips: - For interactive use, request tokens with a lifetime that covers your session (e.g., 4h). - For automated scripts or applications, implement logic to refresh the token proactively before it expires.</p>"},{"location":"configuration-and-management/token-management/#token-revocation","title":"Token Revocation","text":"<p>You can invalidate all active tokens associated with your user account. This is a key security feature if you believe a token has been exposed.</p> <p>To revoke all your tokens, send a <code>DELETE</code> request to the <code>/v1/tokens</code> endpoint.</p> <p><pre><code>curl -sSk -X DELETE \"${MAAS_API_URL}/v1/tokens\" \\\n  -H \"Authorization: Bearer $(oc whoami -t)\"\n</code></pre> This action immediately deletes your underlying Service Account, which invalidates all tokens that have ever been issued for it.  The Service Account will be automatically recreated the next time you request a token.</p> <p>Important</p> <p>For Platform Administrators: Admins can manually revoke a user's tokens by finding and deleting their Service Account  in the appropriate tier namespace (e.g., <code>&lt;instance-name&gt;-tier-premium</code>). This is an effective way to immediately cut  off access for a specific user in response to a security event.</p>"},{"location":"configuration-and-management/token-management/#frequently-asked-questions-faq","title":"Frequently Asked Questions (FAQ)","text":"<p>Q: My tier is wrong or shows as \"free\". How do I fix it?</p> <p>A: Your tier is determined by your group membership in OpenShift. Contact your platform administrator to ensure you  are in the correct user group, which should be mapped to your desired tier in the tier mapping configuration.</p> <p>Q: How long should my tokens be valid for?</p> <p>A: It's a balance of security and convenience. For interactive command-line use, 1-8 hours is common. For applications, request shorter-lived tokens (e.g., 15-60 minutes) and refresh them automatically.</p> <p>Q: Can I have multiple active tokens at once?</p> <p>A: Yes. Each call to the <code>/v1/tokens</code> endpoint issues a new, independent token. All of them will be valid until they expire or are revoked.</p> <p>Q: What happens if the <code>maas-api</code> service is down?</p> <p>A: You will not be able to issue new tokens. However, any existing, non-expired tokens will continue to work for calling models, as the gateway validates them directly with the Kubernetes API.</p> <p>Q: Can I use one token to access multiple different models?</p> <p>A: Yes. Your token grants you access based on your tier's RBAC permissions. If your tier is authorized to use multiple models, a single token will work for all of them.</p>"},{"location":"configuration-and-management/token-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuring Subscription Tiers: For operators - tier setup, RBAC, and rate limiting configuration</li> </ul>"},{"location":"install/maas-setup/","title":"Install Model-as-a-Service","text":"<p>The Model-as-a-Service (MaaS) of ODH project is provided as standalone capability.  Provided you have an OpenShift cluster where you had either:</p> <ul> <li>installed Open Data Hub project;</li> <li>or had installed Red Hat OpenShift AI</li> </ul> <p>then you can proceed to install MaaS capabilities by following this guide.</p> <p>The tools you will need:</p> <ul> <li><code>kubectl</code> or <code>oc</code> client (this guide uses <code>kubectl</code>)</li> <li><code>kustomize</code></li> <li><code>jq</code></li> <li><code>envsubst</code></li> <li><code>base64</code></li> <li><code>cut</code></li> </ul>"},{"location":"install/maas-setup/#install-maas-using-the-kustomize-manifest","title":"Install MaaS using the Kustomize manifest","text":"<p>Install MaaS by running the following commands:</p> <pre><code>export CLUSTER_DOMAIN=$(kubectl get ingresses.config.openshift.io cluster -o jsonpath='{.spec.domain}')\n\nkubectl create namespace maas-api\nkubectl apply --server-side=true \\\n  -f &lt;(kustomize build \"https://github.com/opendatahub-io/maas-billing.git/deployment/overlays/openshift?ref=main\" | \\\n       envsubst '$CLUSTER_DOMAIN')\n</code></pre> <p>The Kustomize manifest will:</p> <ul> <li>Create a Gateway as the ingress point for any traffic related to MaaS (for inference    and for the MaaS API).</li> <li>Install the support MaaS API (<code>Deployment</code>, <code>Service</code>, <code>ServiceAccount</code>,    <code>ClusterRole</code>, <code>ClusterRoleBinding</code>, <code>HTTPRoute</code>, and its <code>AuthPolicy</code>).</li> <li>Install predefined policies: authentication, authorization and rate limits (See    Tier Management)</li> </ul>"},{"location":"install/maas-setup/#policy-audience-adjustment","title":"Policy audience adjustment","text":"<p>The default audience of Kubernetes clusters is usually <code>https://kubernetes.default.svc</code>. You can check the audience of your cluster with the following commands:</p> <pre><code>AUD=\"$(kubectl create token default --duration=10m 2&gt;/dev/null | cut -d. -f2 | base64 -d 2&gt;/dev/null | jq -r '.aud[0]' 2&gt;/dev/null)\"\necho $AUD\n\n# Output:\n#   https://kubernetes.default.svc\n</code></pre> <p>The Kustomize manifest uses the default audience for the installed MaaS API policy. If  the output of the previous script is different from a non-empty string and  <code>https://kubernetes.default.svc</code>, you are required to patch the policy of the MaaS API:</p> <pre><code>kubectl patch authpolicy maas-api-auth-policy -n maas-api --type=merge --patch-file &lt;(echo \"  \nspec:\n  rules:\n    authentication:\n      openshift-identities:\n        kubernetesTokenReview:\n          audiences:\n            - $AUD\n            - maas-default-gateway-sa\")\n</code></pre>"},{"location":"install/maas-setup/#next-steps","title":"Next steps","text":"<ul> <li>Deploy models. In the Quick Start, we provide   sample deployments that you    can use to try the MaaS capability.</li> <li>Perform validation. Follow the validation guide to verify that    MaaS is working correctly.</li> </ul>"},{"location":"install/odh-setup/","title":"Install Open Data Hub project","text":"<p>This guide covers the installation of the Open Data Hub project, with the required configuration to deploy the Model-as-a-Service capability (MaaS).</p> <p>You need a Red Hat OpenShift cluster version 4.19.9 or later. Older OpenShift versions are not suitable.</p> <p>MaaS requires ODH's Model Serving component configured for deploying models with <code>LLMInferenceService</code> resources. The prerequisites for this ODH setup are Kuadrant and the LeaderWorkerSet API (LWS).</p> <p>Tools you will need:</p> <ul> <li>kubectl or oc client (this guide uses kubectl)</li> <li>curl</li> <li>jq</li> </ul> <p>Warning</p> <p>You should choose either to install the ODH project, or Red Hat OpenShift AI (RHOAI).  Follow this guide only if your cluster does not have RHOAI installed.  </p>"},{"location":"install/odh-setup/#install-leaderworkerset-api","title":"Install LeaderWorkerSet API","text":"<p>Install the latest version of LWS by using the kubectl method from LWS official documentation. The following script will do so:</p> <pre><code>GH_LATEST_LWS_ENTRY_URL=\"https://api.github.com/repos/kubernetes-sigs/lws/releases\"\nLATEST_LWS_VERSION=$(curl -sSf ${GH_LATEST_LWS_ENTRY_URL} | jq -r 'sort_by(.tag_name|ltrimstr(\"v\")|split(\".\")|map(tonumber)) | last | .tag_name')\n\nkubectl apply --server-side -f https://github.com/kubernetes-sigs/lws/releases/download/${LATEST_LWS_VERSION}/manifests.yaml\n</code></pre>"},{"location":"install/odh-setup/#verification","title":"Verification","text":"<p>Check that LWS deployments are ready:</p> <pre><code>kubectl get deployments --namespace lws-system\n\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nlws-controller-manager   2/2     2            2           35s\n</code></pre>"},{"location":"install/odh-setup/#install-kuadrant","title":"Install Kuadrant","text":"<p>Kuadrant official documentation is used as a base to install Kuadrant's latest version (v1.3.0+ is required) using the OLM method.</p> <p>Start by creating the <code>kuadrant-system</code> namespace:</p> <pre><code>kubectl create namespace kuadrant-system\n</code></pre> <p>Create an OperatorGroup in the <code>kuadrant-system</code> namespace.</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: kuadrant-operator-group\n  namespace: kuadrant-system\nspec: {}\nEOF\n</code></pre> <p>Note</p> <p>A single OperatorGroup should exist in any given namespace. Check for the existence of multiple OperatorGroups if Kuadrant operator is not deployed  successfully.</p> <p>Configure Kuadrant's CatalogSource:</p> <pre><code># Find latest Kuadrant operator version:\nGH_LATEST_KUADRANT_ENTRY_URL=\"https://api.github.com/repos/Kuadrant/kuadrant-operator/releases/latest\"\nLATEST_KUADRANT_VERSION=$(curl -sSf ${GH_LATEST_KUADRANT_ENTRY_URL} | jq -r '.tag_name')\n\n# Install the CatalogSource\nkubectl apply -f - &lt;&lt;EOF\napiVersion: operators.coreos.com/v1alpha1\nkind: CatalogSource\nmetadata:\n  name: kuadrant-operator-catalog\n  namespace: kuadrant-system\nspec:\n  displayName: Kuadrant Operators\n  image: quay.io/kuadrant/kuadrant-operator-catalog:${LATEST_KUADRANT_VERSION}\n  sourceType: grpc\nEOF\n</code></pre> <p>Deploy the Kuadrant operator, configuring it to work with OpenShift's provided Gateway API implementation:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\n  apiVersion: operators.coreos.com/v1alpha1\n  kind: Subscription\n  metadata:\n    name: kuadrant-operator\n    namespace: kuadrant-system\n  spec:\n    channel: stable\n    installPlanApproval: Automatic\n    name: kuadrant-operator\n    source: kuadrant-operator-catalog\n    sourceNamespace: kuadrant-system\n    config:\n      env:\n      - name: \"ISTIO_GATEWAY_CONTROLLER_NAMES\"\n        value: \"openshift.io/gateway-controller/v1\"\nEOF\n</code></pre>"},{"location":"install/odh-setup/#verification_1","title":"Verification","text":"<p>Check that Kuadrant deployments are ready:</p> <pre><code>kubectl get deployments -n kuadrant-system\n\nNAME                                    READY   UP-TO-DATE   AVAILABLE   AGE\nauthorino-operator                      1/1     1            1           80s\ndns-operator-controller-manager         1/1     1            1           77s\nkuadrant-console-plugin                 1/1     1            1           58s\nkuadrant-operator-controller-manager    1/1     1            1           69s\nlimitador-operator-controller-manager   1/1     1            1           73s\n</code></pre>"},{"location":"install/odh-setup/#install-open-data-hub-with-model-serving","title":"Install Open Data Hub with Model Serving","text":"<p>The Open Data Hub Project (ODH) is installed via its operator, which is available in OpenShift's preconfigured CatalogSource of community operators. Create the following Subscription to install the latest version of ODH Operator (version 3.0 or later is  required for MaaS):</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\n  apiVersion: operators.coreos.com/v1alpha1\n  kind: Subscription\n  metadata:\n    name: opendatahub-operator\n    namespace: openshift-operators\n  spec:\n    channel: fast-3\n    name: opendatahub-operator\n    source: community-operators\n    sourceNamespace: openshift-marketplace\nEOF\n</code></pre> <p>Set up the inference Gateway, required by ODH's Model Serving, by creating the  following resources:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: gateway.networking.k8s.io/v1\nkind: GatewayClass\nmetadata:\n  name: openshift-default\nspec:\n  controllerName: \"openshift.io/gateway-controller/v1\"\n---\napiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: openshift-ai-inference\n  namespace: openshift-ingress\nspec:\n  gatewayClassName: openshift-default\n  listeners:\n   - name: http\n     port: 80\n     protocol: HTTP\n     allowedRoutes:\n       namespaces:\n         from: All\n  infrastructure:\n    labels:\n      serving.kserve.io/gateway: kserve-ingress-gateway\nEOF\n</code></pre> <p>Install the ODH Model Serving component by creating two resources: 1. A <code>DSCInitialization</code> resource to initialize the ODH platform 2. A <code>DataScienceCluster</code> resource to install ODH components</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: dscinitialization.opendatahub.io/v2\nkind: DSCInitialization\nmetadata:\n  name: default-dsci\nspec:\n  applicationsNamespace: opendatahub\n  monitoring:\n    managementState: Managed\n    namespace: opendatahub\n    metrics: {}\n  trustedCABundle:\n    managementState: Managed\n---\napiVersion: datasciencecluster.opendatahub.io/v2\nkind: DataScienceCluster\nmetadata:\n  name: default-dsc\nspec:\n  components:\n    # Components required for MaaS:\n    kserve:\n      managementState: Managed\n      rawDeploymentServiceConfig: Headed\n\n    # Components recommended for MaaS:\n    dashboard:\n      managementState: Managed\nEOF\n</code></pre>"},{"location":"install/prerequisites/","title":"MaaS Installation Overview","text":"<p>Currently, ODH's Model-as-a-Service is provided as a standalone capability that is compatible with the Open Data Hub project (ODH), and with Red Hat OpenShift AI (RHOAI). To install MaaS:</p> <ul> <li>Install the Open Data Hub project,   or install Red Hat OpenShift AI.</li> <li>Install MaaS using Kustomize manifests.</li> </ul> <p>MaaS inherits the platform requirement for a Red Hat OpenShift cluster version 4.19.9 or later, which is the version that has formal support for Gateway API. For earlier OpenShift versions, there are alternatives (e.g. see a guide here), but we provide no support for such setups.</p>"},{"location":"install/prerequisites/#requirements-for-open-data-hub-project","title":"Requirements for Open Data Hub project","text":"<p>MaaS requires Open Data Hub version 3.0 or later, with the Model Serving component enabled (KServe) and properly configured for deploying models with <code>LLMInferenceService</code> resources.</p> <p>A specific requirement for MaaS is to set up ODH's Model Serving with Kuadrant v1.3+, even though ODH can work with earlier Kuadrant versions.</p>"},{"location":"install/prerequisites/#requirements-for-red-hat-openshift-ai","title":"Requirements for Red Hat OpenShift AI","text":"<p>MaaS requires Red Hat OpenShift AI (RHOAI) version 3.0 or later, with the Model Serving component enabled (KServe) and properly configured for deploying models with <code>LLMInferenceService</code> resources.</p> <p>A specific requirement for MaaS is to set up RHOAI Model Serving with Red Hat Connectivity Link (RHCL) v1.2+, even though RHOAI can work with earlier RHCL versions.</p>"},{"location":"install/rhoai-setup/","title":"Install Red Hat OpenShift AI","text":"<p>This guide covers the installation of Red Hat OpenShift AI (RHOAI), with the required configuration to enable the Model-as-a-Service capability (MaaS).</p> <p>You need a Red Hat OpenShift cluster version 4.19.9 or later. Older OpenShift versions are not suitable.</p> <p>MaaS requires RHOAI Model Serving component configured for deploying models with <code>LLMInferenceService</code> resources. The prerequisites for this setup are Red Hat Connectivity Link (RHCL) and the LeaderWorkerSet API (LWS).</p> <p>Tools you will need:</p> <ul> <li>kubectl or oc client (this guide uses kubectl)</li> </ul> <p>Warning</p> <p>You should choose either to install Red Hat OpenShift AI, or the Open Data Hub project (ODH). Follow this guide only if your cluster does not have ODH installed.</p> <p>Note</p> <p>This guide is provided for convenience. In case of any issues or more advanced setups, refer to the Red Hat documentation of the installed components.</p>"},{"location":"install/rhoai-setup/#install-leaderworkerset-api","title":"Install LeaderWorkerSet API","text":"<p>Install Red Hat LeaderWorkerSet API (LWS) Operator from OpenShift's built-in OperatorHub. This can be achieved by applying the following YAML in the cluster:</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: openshift-lws-operator\n---\napiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: leader-worker-set\n  namespace: openshift-lws-operator\nspec:\n  targetNamespaces:\n  - openshift-lws-operator\n---\napiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: leader-worker-set\n  namespace: openshift-lws-operator\nspec:\n  channel: stable-v1.0\n  installPlanApproval: Automatic\n  name: leader-worker-set\n  source: redhat-operators\n  sourceNamespace: openshift-marketplace\n</code></pre> <p>Once the LWS operator is ready, set up the LWS API by applying the following YAML:</p> <pre><code>apiVersion: operator.openshift.io/v1\nkind: LeaderWorkerSetOperator\nmetadata:\n  name: cluster\n  namespace: openshift-lws-operator\nspec:\n  managementState: Managed\n</code></pre> <p>Check Red Hat LWS documentation if you need further guidance.</p>"},{"location":"install/rhoai-setup/#verification","title":"Verification","text":"<p>Check that LWS deployments are ready:</p> <pre><code>kubectl get deployments --namespace openshift-lws-operator\n\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\nlws-controller-manager   2/2     2            2           61s\nopenshift-lws-operator   1/1     1            1           4m26s\n</code></pre>"},{"location":"install/rhoai-setup/#install-red-hat-connectivity-link","title":"Install Red Hat Connectivity Link","text":"<p>Initialize OpenShift's provided Gateway API implementation by creating the following resource:</p> <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: GatewayClass\nmetadata:\n  name: openshift-default\nspec:\n  controllerName: \"openshift.io/gateway-controller/v1\"\n</code></pre> <p>Wait until the GatewayClass resource is accepted:</p> <pre><code>kubectl get gatewayclass openshift-default\n\nNAME                CONTROLLER                           ACCEPTED   AGE\nopenshift-default   openshift.io/gateway-controller/v1   True       52s\n</code></pre> <p>Install Red Hat Connectivity Link (RHCL) Operator from OpenShift's built-in OperatorHub. MaaS requires RHCL v1.2 or later. This can be achieved by applying the following YAML in the cluster:</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: kuadrant-system\n---\napiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: kuadrant-operator-group\n  namespace: kuadrant-system\n---\napiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: kuadrant-operator\n  namespace: kuadrant-system\nspec:\n  channel: stable\n  installPlanApproval: Automatic\n  name: rhcl-operator\n  source: redhat-operators\n  sourceNamespace: openshift-marketplace\n</code></pre> <p>Once the RHCL operator is ready, create a Connectivity Link instance by applying the following YAML:</p> <pre><code>apiVersion: kuadrant.io/v1beta1\nkind: Kuadrant\nmetadata:\n  name: kuadrant\n  namespace: kuadrant-system\n</code></pre> <p>Check RHCL documentation if you need further guidance.</p>"},{"location":"install/rhoai-setup/#verification_1","title":"Verification","text":"<p>Check that RHCL deployments are ready:</p> <pre><code>kubectl get deployments -n kuadrant-system\n\nNAME                                    READY   UP-TO-DATE   AVAILABLE   AGE\nauthorino-operator                      1/1     1            1           80s\ndns-operator-controller-manager         1/1     1            1           77s\nkuadrant-console-plugin                 1/1     1            1           58s\nkuadrant-operator-controller-manager    1/1     1            1           69s\nlimitador-operator-controller-manager   1/1     1            1           73s\nauthorino                               1/1     1            1           81s\nlimitador-limitador                     1/1     1            1           82s\n</code></pre>"},{"location":"install/rhoai-setup/#install-red-hat-openshift-ai-with-model-serving","title":"Install Red Hat OpenShift AI with Model Serving","text":"<p>First, set up the inference Gateway, required by RHOAI's Model Serving, by creating the following resource:</p> <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: openshift-ai-inference\n  namespace: openshift-ingress\nspec:\n  gatewayClassName: openshift-default\n  listeners:\n  - name: http\n    port: 80\n    protocol: HTTP\n    allowedRoutes:\n      namespaces:\n        from: All\n  infrastructure:\n    labels:\n      serving.kserve.io/gateway: kserve-ingress-gateway\n</code></pre> <p>Install Red Hat OpenShift AI (RHOAI) Operator from OpenShift's built-in OperatorHub. MaaS requires RHOAI v3.0 or later. This can be achieved by applying the following YAML in the cluster:</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: redhat-ods-operator\n---\napiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: rhoai3-operatorgroup\n  namespace: redhat-ods-operator\n---\napiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: rhoai3-operator\n  namespace: redhat-ods-operator\nspec:\n  channel: fast-3.x\n  installPlanApproval: Automatic\n  name: rhods-operator\n  source: redhat-operators\n  sourceNamespace: openshift-marketplace\n</code></pre> <p>Once ready, the RHOAI Operator should automatically create a <code>DSCInitialization</code> resource. Install the Model Serving component by creating the following <code>DataScienceCluster</code> resource:</p> <pre><code>apiVersion: datasciencecluster.opendatahub.io/v2\nkind: DataScienceCluster\nmetadata:\n  name: default-dsc\nspec:\n  components:\n    # Components required for MaaS:\n    kserve:\n      managementState: Managed\n      rawDeploymentServiceConfig: Headed\n\n    # Components recommended for MaaS:\n    dashboard:\n      managementState: Managed\n</code></pre> <p>Check RHOAI documentation if you need further guidance.</p>"},{"location":"install/rhoai-setup/#verification_2","title":"Verification","text":"<p>Check that RHOAI Model Serving Deployments are ready:</p> <pre><code>kubectl get deployments -n redhat-ods-applications\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE\nkserve-controller-manager   1/1     1            1           73s\nodh-model-controller        1/1     1            1           79s\nrhods-dashboard             2/2     2            2           78s\n</code></pre>"},{"location":"install/validation/","title":"Validation Guide","text":"<p>This guide provides instructions for validating and testing your MaaS Platform deployment.</p>"},{"location":"install/validation/#manual-validation-recommended","title":"Manual Validation (Recommended)","text":"<p>Follow these steps to validate your deployment and understand each component:</p>"},{"location":"install/validation/#1-get-gateway-endpoint","title":"1. Get Gateway Endpoint","text":"<pre><code>CLUSTER_DOMAIN=$(kubectl get ingresses.config.openshift.io cluster -o jsonpath='{.spec.domain}')\nHOST=\"https://maas.${CLUSTER_DOMAIN}\"\n</code></pre> <p>Note</p> <p>If you haven't created the <code>maas-default-gateway</code> yet, you can use the fallback: <pre><code>HOST=\"https://gateway.${CLUSTER_DOMAIN}\"\n</code></pre></p>"},{"location":"install/validation/#2-get-authentication-token","title":"2. Get Authentication Token","text":"<p>For OpenShift:</p> <pre><code>TOKEN_RESPONSE=$(curl -sSk \\\n  -H \"Authorization: Bearer $(oc whoami -t)\" \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{\"expiration\": \"10m\"}' \\\n  \"${HOST}/maas-api/v1/tokens\")\n\nTOKEN=$(echo $TOKEN_RESPONSE | jq -r .token)\n</code></pre> <p>Note</p> <p>For more information about how tokens work, see Understanding Token Management.</p>"},{"location":"install/validation/#3-list-available-models","title":"3. List Available Models","text":"<pre><code>MODELS=$(curl -sSk ${HOST}/maas-api/v1/models \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer $TOKEN\" | jq -r .)\n\necho $MODELS | jq .\nMODEL_NAME=$(echo $MODELS | jq -r '.data[0].id')\n# Get the full URL which includes the LLMInferenceService resource name in the path\nMODEL_URL=$(echo $MODELS | jq -r '.data[0].url')\n\necho \"Model URL: $MODEL_URL\"\n</code></pre>"},{"location":"install/validation/#4-test-model-inference-endpoint","title":"4. Test Model Inference Endpoint","text":"<p>Send a request to the model endpoint (should get a 200 OK response):</p> <pre><code>curl -sSk -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"model\\\": \\\"${MODEL_NAME}\\\", \\\"prompt\\\": \\\"Hello\\\", \\\"max_tokens\\\": 50}\" \\\n  \"${MODEL_URL}/v1/completions\"\n</code></pre>"},{"location":"install/validation/#5-test-authorization-enforcement","title":"5. Test Authorization Enforcement","text":"<p>Send a request to the model endpoint without a token (should get a 401 Unauthorized response):</p> <pre><code>curl -sSk -H \"Content-Type: application/json\" \\\n  -d \"{\\\"model\\\": \\\"${MODEL_NAME}\\\", \\\"prompt\\\": \\\"Hello\\\", \\\"max_tokens\\\": 50}\" \\\n  \"${MODEL_URL}/v1/completions\" -v\n</code></pre>"},{"location":"install/validation/#6-test-rate-limiting","title":"6. Test Rate Limiting","text":"<p>Send multiple requests to trigger rate limit (should get 200 OK followed by 429 Rate Limit Exceeded after about 4 requests):</p> <pre><code>for i in {1..16}; do\n  curl -sSk -o /dev/null -w \"%{http_code}\\n\" \\\n    -H \"Authorization: Bearer $TOKEN\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"model\\\": \\\"${MODEL_NAME}\\\", \\\"prompt\\\": \\\"Hello\\\", \\\"max_tokens\\\": 50}\" \\\n    \"${MODEL_URL}/v1/completions\"\ndone\n</code></pre>"},{"location":"install/validation/#7-verify-component-status","title":"7. Verify Component Status","text":"<p>Check that all components are running:</p> <pre><code>kubectl get pods -n maas-api\nkubectl get pods -n kuadrant-system\nkubectl get pods -n kserve\nkubectl get pods -n llm\n</code></pre> <p>Check Gateway status:</p> <pre><code>kubectl get gateway -n openshift-ingress maas-default-gateway\n</code></pre> <p>Check that policies are enforced:</p> <pre><code>kubectl get authpolicy -A\nkubectl get tokenratelimitpolicy -A\n\n# Check LLMInferenceServices are ready\nkubectl get llminferenceservices -n llm\n</code></pre> <p>See the deployment scripts documentation at <code>deployment/scripts/README.md</code> for more information about validation and troubleshooting.</p>"},{"location":"install/validation/#automated-validation","title":"Automated Validation","text":"<p>For faster validation, you can use the automated validation script to run the manual validation steps more quickly:</p> <pre><code>./deployment/scripts/validate-deployment.sh\n</code></pre> <p>The script automates the manual validation steps above and provides detailed feedback with specific suggestions for fixing any issues found. This is useful when you need to quickly verify deployment status, but understanding the manual steps above helps with troubleshooting.</p>"},{"location":"install/validation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"install/validation/#common-issues","title":"Common Issues","text":"<ol> <li>Getting <code>501</code> Not Implemented errors: Traffic is not making it to the Gateway.<ul> <li> Verify Gateway status and HTTPRoute configuration</li> </ul> </li> <li>Getting <code>401</code> Unauthorized errors when trying to get a token: Authentication maas-api is not working.<ul> <li> Verify <code>maas-api-auth-policy</code> AuthPolicy is applied</li> <li> Validate the AuthPolicy audience matches the token audience (audiences: [\"https://kubernetes.default.svc\", \"maas-default-gateway-sa\"])</li> </ul> </li> <li>Getting <code>401</code> errors when trying to get models: Authentication is not working for the models endpoint.<ul> <li> Create a new token (default expiration is 10 minutes)</li> <li> Verify <code>gateway-auth-policy</code> AuthPolicy is applied</li> <li> Validate that <code>system:serviceaccounts:maas-default-gateway-tier-{TIER}</code> has <code>post</code> access to the <code>llminferenceservices</code> resource<ul> <li>Note: this should be automated by the ODH Controller</li> </ul> </li> </ul> </li> <li>Getting <code>404</code> errors when trying to get models: The models endpoint is not working.<ul> <li> Verify <code>model-route</code> HTTPRoute exist and is applied</li> <li> Verify the model is deployed and the <code>LLMInferenceService</code> has the <code>maas-default-gateway</code> gateway specified</li> <li> Verify that the model is recognized by maas-api by checking the <code>maas-api/v1/models</code> endpoint (see List Available Models)</li> </ul> </li> <li>Rate limiting not working: Verify AuthPolicy and TokenRateLimitPolicy are applied<ul> <li> Verify <code>gateway-rate-limits</code> RateLimitPolicy is applied</li> <li> Verify <code>gateway-token-rate-limits</code> TokenRateLimitPolicy is applied</li> <li> Verify the model is deployed and the <code>LLMInferenceService</code> has the <code>maas-default-gateway</code> gateway specified</li> <li> Verify that the model is rate limited by checking the inference endpoint (see Test Rate Limiting)</li> <li> Verify that the model is token rate limited by checking the inference endpoint (see Test Rate Limiting)</li> </ul> </li> <li>Routes not accessible (503 errors): Check MaaS Default Gateway status and HTTPRoute configuration<ul> <li> Verify Gateway is in <code>Programmed</code> state: <code>kubectl get gateway -n openshift-ingress maas-default-gateway</code></li> <li> Check HTTPRoute configuration and status</li> </ul> </li> </ol>"},{"location":"user-guide/self-service-model-access/","title":"Self-Service Model Access","text":"<p>This guide is for end users who want to use AI models through the MaaS platform.</p>"},{"location":"user-guide/self-service-model-access/#what-is-maas","title":"\ud83c\udfaf What is MaaS?","text":"<p>The Model-as-a-Service (MaaS) platform provides access to AI models through a simple API. Your organization's administrator has set up the platform and configured access for your team.</p>"},{"location":"user-guide/self-service-model-access/#getting-your-access-token","title":"Getting Your Access Token","text":"<p>Tip</p> <p>For a detailed explanation of how token authentication works, including the underlying service account architecture and security model, see Understanding Token Management.</p>"},{"location":"user-guide/self-service-model-access/#step-1-get-your-openshift-authentication-token","title":"Step 1: Get Your OpenShift Authentication Token","text":"<p>First, you need your OpenShift token to prove your identity to the maas-api.</p> <pre><code># Log in to your OpenShift cluster if you haven't already\noc login ...\n\n# Get your current OpenShift authentication token\nOC_TOKEN=$(oc whoami -t)\n</code></pre>"},{"location":"user-guide/self-service-model-access/#step-2-request-an-access-token-from-the-api","title":"Step 2: Request an Access Token from the API","text":"<p>Next, use that OpenShift token to call the maas-api <code>/v1/tokens</code> endpoint. You can specify the desired expiration time; the default is 4 hours.</p> <pre><code>CLUSTER_DOMAIN=$(kubectl get ingresses.config.openshift.io cluster -o jsonpath='{.spec.domain}')\nMAAS_API_URL=\"https://maas.${CLUSTER_DOMAIN}\"\n\nTOKEN_RESPONSE=$(curl -sSk \\\n  -H \"Authorization: Bearer ${OC_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{\"expiration\": \"15m\"}' \\\n  \"${MAAS_API_URL}/maas-api/v1/tokens\")\n\nACCESS_TOKEN=$(echo $TOKEN_RESPONSE | jq -r .token)\n\necho $ACCESS_TOKEN\n</code></pre>"},{"location":"user-guide/self-service-model-access/#token-lifecycle","title":"Token Lifecycle","text":"<ul> <li>Default lifetime: 4 hours (configurable when requesting)</li> <li>Maximum lifetime: Determined by cluster configuration</li> <li>Refresh: Request a new token before expiration</li> <li>Revocation: Tokens can be revoked if compromised</li> </ul>"},{"location":"user-guide/self-service-model-access/#discovering-models","title":"Discovering Models","text":""},{"location":"user-guide/self-service-model-access/#list-available-models","title":"List Available Models","text":"<p>Get a list of models available to your tier:</p> <pre><code>MODELS=$(curl \"${MAAS_API_URL}/v1/models\" \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer ${ACCESS_TOKEN}\")\n\necho $MODELS | jq .\n</code></pre> <p>Example response:</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"simulator\",\n      \"name\": \"Simulator Model\",\n      \"url\": \"https://gateway.your-domain.com/simulator/v1/chat/completions\",\n      \"tier\": \"free\"\n    },\n    {\n      \"id\": \"qwen3\",\n      \"name\": \"Qwen3 Model\",\n      \"url\": \"https://gateway.your-domain.com/qwen3/v1/chat/completions\",\n      \"tier\": \"premium\"\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/self-service-model-access/#get-model-details","title":"Get Model Details","text":"<p>Get detailed information about a specific model:</p> <pre><code>MODEL_ID=\"simulator\"\nMODEL_INFO=$(curl \"${MAAS_API_URL}/v1/models\" \\\n    -H \"Authorization: Bearer ${ACCESS_TOKEN}\" | \\\n    jq --arg model \"$MODEL_ID\" '.data[] | select(.id == $model)')\n\necho $MODEL_INFO | jq .\n</code></pre>"},{"location":"user-guide/self-service-model-access/#making-inference-requests","title":"Making Inference Requests","text":""},{"location":"user-guide/self-service-model-access/#basic-chat-completion","title":"Basic Chat Completion","text":"<p>Make a simple chat completion request:</p> <pre><code># First, get the model URL from the models endpoint\nMODELS=$(curl \"${MAAS_API_URL}/v1/models\" \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer ${ACCESS_TOKEN}\")\nMODEL_URL=$(echo $MODELS | jq -r '.data[0].url')\nMODEL_NAME=$(echo $MODELS | jq -r '.data[0].id')\n\ncurl -sSk \\\n  -H \"Authorization: Bearer ${ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n        \\\"model\\\": \\\"${MODEL_NAME}\\\",\n        \\\"messages\\\": [\n          {\n            \\\"role\\\": \\\"user\\\",\n            \\\"content\\\": \\\"Hello, how are you?\\\"\n          }\n        ],\n        \\\"max_tokens\\\": 100\n      }\" \\\n  \"${MODEL_URL}/v1/chat/completions\"\n</code></pre>"},{"location":"user-guide/self-service-model-access/#streaming-chat-completion","title":"Streaming Chat Completion","text":"<p>For streaming responses, add <code>\"stream\": true</code> to the request and use <code>--no-buffer</code> to process the response in real-time:</p> <pre><code>curl -sSk --no-buffer \\\n  -H \"Authorization: Bearer ${ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\n        \\\"model\\\": \\\"${MODEL_NAME}\\\",\n        \\\"messages\\\": [\n          {\n            \\\"role\\\": \\\"user\\\",\n            \\\"content\\\": \\\"Hello, how are you?\\\"\n          }\n        ],\n        \\\"max_tokens\\\": 100,\n        \\\"stream\\\": true\n      }\" \\\n  \"${MODEL_URL}/v1/chat/completions\"\n</code></pre>"},{"location":"user-guide/self-service-model-access/#understanding-your-access-level","title":"Understanding Your Access Level","text":"<p>Your access is determined by your tier, which controls:</p> <ul> <li>Available models - Which AI models you can use</li> <li>Request limits - How many requests per minute</li> <li>Token limits - Maximum tokens per request</li> <li>Features - Advanced capabilities available</li> </ul>"},{"location":"user-guide/self-service-model-access/#default-tiers","title":"Default Tiers","text":"Tier Requests/min Tokens/min Free 5 100 Premium 20 50,000 Enterprise 50 100,000"},{"location":"user-guide/self-service-model-access/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/self-service-model-access/#common-error-responses","title":"Common Error Responses","text":"<p>401 Unauthorized</p> <pre><code>{\n  \"error\": {\n    \"message\": \"Invalid authentication token\",\n    \"type\": \"invalid_request_error\",\n    \"code\": \"invalid_api_key\"\n  }\n}\n</code></pre> <p>403 Forbidden</p> <pre><code>{\n  \"error\": {\n    \"message\": \"Insufficient permissions for this model\",\n    \"type\": \"permission_error\",\n    \"code\": \"access_denied\"\n  }\n}\n</code></pre> <p>429 Too Many Requests</p> <pre><code>{\n  \"error\": {\n    \"message\": \"Rate limit exceeded\",\n    \"type\": \"rate_limit_error\",\n    \"code\": \"rate_limit_exceeded\"\n  }\n}\n</code></pre>"},{"location":"user-guide/self-service-model-access/#monitoring-usage","title":"Monitoring Usage","text":"<p>Check your current usage through response headers:</p> <pre><code># Make a request and check headers\ncurl -I -sSk \\\n  -H \"Authorization: Bearer ${ACCESS_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\": \"simulator\", \"messages\": [{\"role\": \"user\", \"content\": \"test\"}]}' \\\n  \"${MODEL_URL}/v1/chat/completions\" | grep -i \"x-ratelimit\"\n</code></pre>"},{"location":"user-guide/self-service-model-access/#common-issues","title":"\u26a0\ufe0f Common Issues","text":""},{"location":"user-guide/self-service-model-access/#authentication-errors","title":"Authentication Errors","text":"<p>Problem: <code>401 Unauthorized</code></p> <p>Solution: Check your token and ensure it's correctly formatted:</p> <pre><code># Correct format\n-H \"Authorization: Bearer YOUR_TOKEN\"\n\n# Wrong format\n-H \"Authorization: YOUR_TOKEN\"\n</code></pre>"},{"location":"user-guide/self-service-model-access/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Problem: <code>429 Too Many Requests</code></p> <p>Solution: Wait before making more requests, or contact your administrator to upgrade your tier.</p>"},{"location":"user-guide/self-service-model-access/#model-not-available","title":"Model Not Available","text":"<p>Problem: <code>404 Model Not Found</code></p> <p>Solution: Check which models are available in your tier:</p> <pre><code>curl -X GET \"${MAAS_API_URL}/v1/models\" \\\n  -H \"Authorization: Bearer ${ACCESS_TOKEN}\"\n</code></pre>"}]}